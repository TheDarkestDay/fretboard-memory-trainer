<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Audio Pitch Detector</title>
</head>
<body>
  <h1>Audio Pitch Detector</h1>
  <p id="output">Waiting for audio input...</p>

  <script>
    const output = document.getElementById('output');

    async function startPitchDetection() {
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();

      analyser.fftSize = 2048;
      const buffer = new Float32Array(analyser.fftSize);

      source.connect(analyser);
      await audioContext.resume();

      function autoCorrelate(buf, sampleRate) {
        let SIZE = buf.length;
        let rms = 0;

        for (let i = 0; i < SIZE; i++) {
          let val = buf[i];
          rms += val * val;
        }
        rms = Math.sqrt(rms / SIZE);
        if (rms < 0.01) return -1; // too quiet

        let r1 = 0, r2 = SIZE - 1, threshold = 0.2;
        for (let i = 0; i < SIZE / 2; i++) {
          if (Math.abs(buf[i]) < threshold) {
            r1 = i;
            break;
          }
        }
        for (let i = 1; i < SIZE / 2; i++) {
          if (Math.abs(buf[SIZE - i]) < threshold) {
            r2 = SIZE - i;
            break;
          }
        }

        buf = buf.slice(r1, r2);
        SIZE = buf.length;

        const c = new Array(SIZE).fill(0);
        for (let i = 0; i < SIZE; i++) {
          for (let j = 0; j < SIZE - i; j++) {
            c[i] = c[i] + buf[j] * buf[j + i];
          }
        }

        let d = 0;
        while (c[d] > c[d + 1]) d++;

        let maxval = -1, maxpos = -1;
        for (let i = d; i < SIZE; i++) {
          if (c[i] > maxval) {
            maxval = c[i];
            maxpos = i;
          }
        }

        let T0 = maxpos;

        return sampleRate / T0;
      }

      function frequencyToNote(freq) {
        const A4 = 440;
        const noteNames = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
        const n = Math.round(12 * Math.log2(freq / A4));
        const noteIndex = (n + 69) % 12;
        const octave = Math.floor((n + 69) / 12);
        return `${noteNames[noteIndex]}${octave}`;
      }

      function detectPitch() {
        analyser.getFloatTimeDomainData(buffer);
        const isSilent = buffer.every(sample => sample === 0);
        console.log("Silent:", isSilent);
        const frequency = autoCorrelate(buffer, audioContext.sampleRate);
        if (frequency !== -1) {
          const note = frequencyToNote(frequency);
          output.textContent = `Detected pitch: ${note} (${frequency.toFixed(2)} Hz)`;
        } else {
          output.textContent = `Listening...`;
        }
        requestAnimationFrame(detectPitch);
      }

      detectPitch();
    }

    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
      startPitchDetection().catch(err => {
        output.textContent = 'Error accessing microphone.';
        console.error(err);
      });
    } else {
      output.textContent = 'getUserMedia not supported in this browser.';
    }
  </script>
</body>
</html>

